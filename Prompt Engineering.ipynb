{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_template = ''' I want you to act as a acting financial advisor for people. In an easy way, explain the {financial_concept} like  explaining the concept to a 5 year old kid. You may include anectodes as well. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables = ['financial_concept'], template = demo_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I want you to act as a acting financial advisor for people. In an easy way, explain the income tax like  explaining the concept to a 5 year old kid. You may include anectodes as well. '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(financial_concept='income tax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_key = \"********************************************\" \n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm  = OpenAI(temperature = 0.7)\n",
    "chain1 = LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nHey there kiddo! Have you ever heard of a piggy bank? It's a special bank where you can save your money and watch it grow over time. Well, mutual funds are kind of like a piggy bank for grown-ups!\\n\\nYou see, a lot of adults have a hard time figuring out what to do with their money. They want to save it for the future, but they don't know where to put it. That's where mutual funds come in. \\n\\nThink of a mutual fund as a big piggy bank that a bunch of people put their money into. Just like how you put your allowance into your piggy bank, grown-ups put their money into a mutual fund. But instead of just sitting there, the money in the mutual fund is used to buy little pieces of different companies, kind of like buying little pieces of candy from the store.\\n\\nNow, just like how you can't eat all the candy from the store right away, the companies in the mutual fund grow slowly over time. That means the little pieces of candy, I mean stocks, that the mutual fund bought also grow in value. And since the mutual fund has a little bit of each company, if one company doesn't do well, it's okay because the others can\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.run('Mutual Funds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nHello little one! Have you ever heard of something called GDP? It stands for Gross Domestic Product. Don't worry if it sounds a bit fancy, it's actually a very simple concept.\\n\\nImagine that your parents have a lemonade stand. They make really yummy lemonade and sell it to people in the neighborhood. Every time they sell a cup of lemonade, they make some money, right? Well, the total amount of money they make from selling lemonade is like the GDP of their lemonade stand.\\n\\nNow, let's say your neighbor also has a lemonade stand. Her lemonade is not as tasty as your parents' but she sells a lot more cups. So, even though your parents' lemonade is better, the neighbor makes more money. This is kind of like how different countries have different GDPs. Some countries may have more money because they sell a lot of things, even if those things are not as good as what other countries sell.\\n\\nBut remember, GDP is not just about selling things. It also includes things like how much money people make from their jobs, how much money the government spends on important things like schools and hospitals, and how much money people save for the future.\\n\\nOh, and here's a fun fact - did you\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1.run('GDP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In an easy way translate the following sentence 'How are you ?' into 'Kannada' \""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Language Translation\n",
    "demo_template_2 = \"In an easy way translate the following sentence '{sentence}' into '{target_language}' \"\n",
    "language_prompt =  PromptTemplate(input_variables = ['sentence','target_language'], template = demo_template_2)\n",
    "language_prompt.format(sentence=\"How are you ?\", target_language=\"Kannada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shash\\anaconda3\\envs\\genai\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Hello, How are you ?',\n",
       " 'target_language': 'Kannada',\n",
       " 'text': '\\n\\n\"ಹಲೋ, ನೀವು ಹೇಗಿದ್ದೀರಿ?\"'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = LLMChain(llm=llm,prompt = language_prompt)\n",
    "chain2({'sentence': \"Hello, How are you ?\", 'target_language':'Kannada'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Hello, How are you ?',\n",
       " 'target_language': 'German',\n",
       " 'text': '\\n\\nHallo, wie geht es dir?'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = LLMChain(llm=llm,prompt = language_prompt)\n",
    "chain2({'sentence': \"Hello, How are you ?\", 'target_language':'German'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Hello, How are you ?',\n",
       " 'target_language': 'Spanish',\n",
       " 'text': '\\n\\n¡Hola, ¿Cómo estás?'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2 = LLMChain(llm=llm,prompt = language_prompt)\n",
    "chain2({'sentence': \"Hello, How are you ?\", 'target_language':'Spanish'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# First, create the list of few shot examples.\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]\n",
    "\n",
    "# Next, we specify the template to format the examples we have provided.\n",
    "# We use the `PromptTemplate` class for this.\n",
    "example_formatter_template = \"\"\"Word: {word}\n",
    "Antonym: {antonym}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"word\", \"antonym\"],\n",
    "    template=example_formatter_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    # These are the examples we want to insert into the prompt.\n",
    "    examples=examples,\n",
    "    # This is how we want to format the examples when we insert them into the prompt.\n",
    "    example_prompt=example_prompt,\n",
    "    # The prefix is some text that goes before the examples in the prompt.\n",
    "    # Usually, this consists of intructions.\n",
    "    prefix=\"Give the antonym of every input\\n\",\n",
    "    # The suffix is some text that goes after the examples in the prompt.\n",
    "    # Usually, this is where the user input will go\n",
    "    suffix=\"Word: {input}\\nAntonym: \",\n",
    "    # The input variables are the variables that the overall prompt expects.\n",
    "    input_variables=[\"input\"],\n",
    "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with.\n",
    "    example_separator=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: happy\n",
      "Antonym: sad\n",
      "\n",
      "Word: tall\n",
      "Antonym: short\n",
      "\n",
      "Word: big\n",
      "Antonym: \n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input='big'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'big', 'text': 'small'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=LLMChain(llm=llm,prompt=few_shot_prompt)\n",
    "chain({'input':\"big\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
